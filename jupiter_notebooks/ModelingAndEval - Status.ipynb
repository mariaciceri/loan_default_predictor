{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification**\n",
    "\n",
    "## Objectives\n",
    "+ Fit and evaluate a classification model to predict loan default.\n",
    "\n",
    "## Inputs\n",
    "+ outputs/datasets/collection/LoanDefault.csv\n",
    "+ Instructions on which variables to use for data cleaning and feature engineering.\n",
    "\n",
    "## Outputs\n",
    "+ Train set (features and target)\n",
    "+ Test set (features and target)\n",
    "+ Modeling pipeline\n",
    "+ Feature importance plot\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Start by changing working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd() # get the current working directory\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir)) # change directory to parent directory\n",
    "print(\"The directory you are in is:\", os.getcwd()) # print current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/LoanDefault.csv\")\n",
    "      .drop(labels=[\"ID\", \"year\"], axis=1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline with data\n",
    "\n",
    "### Pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom transformer was created to impute missing values in the LTV feature based on the relationship between loan amount and property value. Then, the pipeline for data cleaning and engineering is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LTVImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class to impute missing values in the LTV column of a DataFrame.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Doesn't need fitting, it just needs to apply the transformation.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the data by imputing missing values in the LTV column\n",
    "        using the formula.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy.loc[X_copy[\"LTV\"].isnull(), \"LTV\"] = (\n",
    "            X_copy[\"loan_amount\"] / X_copy[\"property_value\"]\n",
    "            ) * 100\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer, ArbitraryNumberImputer\n",
    "from feature_engine.outliers import OutlierTrimmer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.transformation import LogTransformer, YeoJohnsonTransformer\n",
    "\n",
    "def PipelineDataCleaningAndEngineering():\n",
    "\n",
    "    # Categorical features and numerical features\n",
    "    categorical_variables = ['loan_limit','Gender','approv_in_adv',\n",
    "                             'loan_type','loan_purpose','Credit_Worthiness',\n",
    "                             'open_credit','business_or_commercial',\n",
    "                             'Neg_ammortization','interest_only',\n",
    "                             'lump_sum_payment','construction_type',\n",
    "                             'occupancy_type','Secured_by','total_units',\n",
    "                             'credit_type','co-applicant_credit_type',\n",
    "                             'age','submission_of_application','Region',\n",
    "                             'Security_Type']\n",
    "    median_variables = [\"Upfront_charges\",\n",
    "                    \"rate_of_interest\",\n",
    "                    \"property_value\",\n",
    "                    \"income\"]\n",
    "    mean_variables = [\"Interest_rate_spread\", \"dtir1\"]\n",
    "    var_to_log = [\"loan_amount\", \"property_value\"]\n",
    "    var_to_yeo = [\"rate_of_interest\"]\n",
    "\n",
    "    # Impute missing values for categorical features\n",
    "    categorical_imputer = CategoricalImputer(imputation_method=\"frequent\")\n",
    "\n",
    "    # Impute missing values for numerical features\n",
    "    numerical_imputer_median = MeanMedianImputer(imputation_method=\"median\", variables=median_variables)\n",
    "    numerical_imputer_mean = MeanMedianImputer(imputation_method=\"mean\", variables=mean_variables)\n",
    "    numerical_imputer_max = ArbitraryNumberImputer(arbitrary_number=360.0, variables=[\"term\"])\n",
    "\n",
    "    # Outlier removal\n",
    "    outlier_trimmer = OutlierTrimmer(capping_method=\"quantiles\", fold=0.05, variables=[\"LTV\"])\n",
    "\n",
    "    # Encoding\n",
    "    encoder = OrdinalEncoder(encoding_method=\"arbitrary\", variables=categorical_variables)\n",
    "\n",
    "    # Variable transformations (log and Yeo-Johnson)\n",
    "    log_transf = LogTransformer(variables=var_to_log)\n",
    "    yeo_transf = YeoJohnsonTransformer(variables=var_to_yeo)\n",
    "\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"CategoricalImputer\", categorical_imputer),\n",
    "        (\"NumericalImputerMedian\", numerical_imputer_median),\n",
    "        (\"NumericalImputerMean\", numerical_imputer_mean),\n",
    "        (\"NumericalImputerMax\", numerical_imputer_max),\n",
    "        (\"LTVImputer\", LTVImputer()),\n",
    "        (\"OutlierTrimmer\", outlier_trimmer),\n",
    "        (\"Encoder\", encoder),\n",
    "        (\"LogTransformer\", log_transf),\n",
    "        (\"YeoJohnsonTransformer\", yeo_transf)\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "PipelineDataCleaningAndEngineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def PipelineClf(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a custom function provided by Code Institute, we performed a grid search across several algorithms with standard hyperparameters to identify the best-performing model for our case. Both tree-based models and logistic regression were selected, as this is a binary classification problem based on structured tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineClf(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['Status'], axis=1),\n",
    "    df['Status'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the dataset into training and test sets, we applied fitting and transformation steps. Since some rows were removed during preprocessing (due to outlier removal), we used `.loc` to realign the target variables with their corresponding feature sets, ensuring that each feature row is correctly matched to its target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndEngineering()\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
    "y_train = y_train.loc[X_train.index]\n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "y_test = y_test.loc[X_test.index]\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, no specific techniques to handle class imbalance were applied, as the chosen model is already capable of making accurate predictions without the need for additional adjustments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch CV\n",
    "\n",
    "Use standard hyperparameters to find the best algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"LogisticRegression\": {},\n",
    "    \"XGBClassifier\": {},\n",
    "    \"DecisionTreeClassifier\": {},\n",
    "    \"RandomForestClassifier\": {},\n",
    "    \"GradientBoostingClassifier\": {},\n",
    "    \"ExtraTreesClassifier\": {},\n",
    "    \"AdaBoostClassifier\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the custom function and check the results for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring = make_scorer(recall_score, pos_label=1),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models, except for linear regression, performed excellently. The next step to finalize the model choice is to analyze the most important features and their contributions.\n",
    "\n",
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ExtraTreesClassifier has emerged as the best estimator, as it utilizes a wider range of features. Upon reviewing the confusion matrix, it showed the fewest incorrect predictions compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipeline_clf = grid_search_pipelines[\"ExtraTreesClassifier\"].best_estimator_\n",
    "\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\n",
    "    'Importance': pipeline_clf['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# re-assign best_features order\n",
    "best_features = df_feature_importance['Feature'].to_list()\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation was also applied to determine the values for recall and F1 score, as these are the most crucial metrics for this study. Both metrics achieved a perfect score of 1, which is excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_recall = cross_val_score(pipeline_clf, X_train, y_train, cv=5,scoring=\"recall\")\n",
    "scores_f1 = cross_val_score(pipeline_clf, X_train, y_train, cv=5, scoring=\"f1\")\n",
    "\n",
    "print(\"\"\"%0.2f recall with a standard deviation of %0.2f \n",
    "and %0.2f F1 with standard deviation of %0.2f\"\"\" % \n",
    "(scores_recall.mean(), scores_recall.std(), \n",
    " scores_f1.mean(), scores_f1.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Create confusion matrices\n",
    "\n",
    "sets = [(X_train, y_train, \"Train set\"), (X_test, y_test, \"Test set\")]\n",
    "\n",
    "for X_set, y_set, name in sets:\n",
    "    predictions = pipeline_clf.predict(X_set)\n",
    "    cm = confusion_matrix(y_set, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                    display_labels=[\"Not Defaulted\", \"Defaulted\"])\n",
    "    disp.plot(cmap=\"gist_stern\")\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need for a detailed report from the confusion matrix, as the model is predicting with near-perfect accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will simplify the pipeline by selecting only the most important features, which will help optimize computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit  using only best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimizedModel():\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ExtraTreesClassifier\", ExtraTreesClassifier()),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute and Split dataset\n",
    "\n",
    "Imputation had to be performed separately, as integrating it into the pipeline was causing unexplainable issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy().filter(items=(best_features+[\"Status\"]))\n",
    "\n",
    "impute_categorical = CategoricalImputer(imputation_method=\"frequent\")\n",
    "df_cleaned = impute_categorical.fit_transform(df_cleaned)\n",
    "\n",
    "ordinal_encode = OrdinalEncoder(encoding_method=\"arbitrary\")\n",
    "df_cleaned = ordinal_encode.fit_transform(df_cleaned)\n",
    "\n",
    "impute_meadian = MeanMedianImputer(\n",
    "                                imputation_method=\"median\",\n",
    "                                variables=[\"Upfront_charges\",\n",
    "                                           \"rate_of_interest\"])\n",
    "df_cleaned = impute_meadian.fit_transform(df_cleaned)\n",
    "\n",
    "impute_mean = MeanMedianImputer(\n",
    "                                imputation_method=\"mean\",\n",
    "                                variables=[\"Interest_rate_spread\", \"dtir1\"])\n",
    "df_cleaned = impute_mean.fit_transform(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.isnull().sum() #check for nulls, confirming the imputation worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_cleaned.drop(['Status'], axis=1),\n",
    "    df_cleaned[\"Status\"],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimized_model = PipelineOptimizedModel()\n",
    "pipeline_optimized_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the model's performance remained unchanged, as these were the features utilized even when others were available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [(X_train, y_train, \"Train set\"), (X_test, y_test, \"Test set\")]\n",
    "\n",
    "for X_set, y_set, name in sets:\n",
    "    predictions = pipeline_optimized_model.predict(X_set)\n",
    "    cm = confusion_matrix(y_set, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=[\"Not Defaulted\", \"Defaulted\"])\n",
    "    disp.plot(cmap=\"gist_stern\", values_format='d')\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to repo\n",
    "\n",
    "\n",
    "We will generate the following files\n",
    "\n",
    "+ Train set\n",
    "+ Test set\n",
    "+ Modeling pipeline\n",
    "+ features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_status/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)\n",
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)\n",
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimized_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=pipeline_optimized_model, filename=f\"{file_path}/pipeline_optimized_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
